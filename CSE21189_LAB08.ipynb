{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YSC_XjMFC37C"
      },
      "source": [
        "BL.EN.U4CSE21189 ; Siddhant Ashwani ; CSE - C"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ntlA0CgnC37H"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from collections import defaultdict\n",
        "from scipy.stats import chi2_contingency\n",
        "from itertools import product   # Using itertools to go through the dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import GaussianNB  # Gaussian Naive Bayes is great for numeric input. Applying Ordinal encoding for numeric conversion.\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import numpy as np\n",
        "import pandas as pd  # Importing pandas for data handling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zRK93Z7pC37M"
      },
      "source": [
        "A1. For the data provided below, calculate the prior probability for each class."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Sea0DCdvC37O"
      },
      "outputs": [],
      "source": [
        "#prior probability = probability of an event before it is collected\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YT5-HoLFC37R",
        "outputId": "9b510bd6-6339-4856-ace1-667967fe3c32"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prior Probabilities for New Data:\n",
            "P(yes) = 0.5714\n",
            "P(no) = 0.4286\n"
          ]
        }
      ],
      "source": [
        "# Data samples\n",
        "new_samples = [\n",
        "    {'age': '<=30', 'income': 'high', 'student': 'no', 'credit_rating': 'fair', 'purchase_decision': 'no'},\n",
        "    {'age': '<=30', 'income': 'high', 'student': 'no', 'credit_rating': 'excellent', 'purchase_decision': 'no'},\n",
        "    {'age': '31..40', 'income': 'high', 'student': 'no', 'credit_rating': 'fair', 'purchase_decision': 'yes'},\n",
        "    {'age': '>40', 'income': 'medium', 'student': 'no', 'credit_rating': 'fair', 'purchase_decision': 'yes'},\n",
        "    {'age': '>40', 'income': 'low', 'student': 'yes', 'credit_rating': 'fair', 'purchase_decision': 'yes'},\n",
        "    {'age': '>40', 'income': 'low', 'student': 'yes', 'credit_rating': 'excellent', 'purchase_decision': 'no'},\n",
        "    {'age': '31..40', 'income': 'low', 'student': 'yes', 'credit_rating': 'excellent', 'purchase_decision': 'yes'},\n",
        "    {'age': '<=30', 'income': 'medium', 'student': 'no', 'credit_rating': 'fair', 'purchase_decision': 'no'},\n",
        "    {'age': '<=30', 'income': 'low', 'student': 'yes', 'credit_rating': 'fair', 'purchase_decision': 'yes'},\n",
        "    {'age': '>40', 'income': 'medium', 'student': 'yes', 'credit_rating': 'fair', 'purchase_decision': 'yes'},\n",
        "    {'age': '<=30', 'income': 'medium', 'student': 'yes', 'credit_rating': 'excellent', 'purchase_decision': 'yes'},\n",
        "    {'age': '31..40', 'income': 'high', 'student': 'no', 'credit_rating': 'excellent', 'purchase_decision': 'yes'},\n",
        "    {'age': '31..40', 'income': 'medium', 'student': 'yes', 'credit_rating': 'fair', 'purchase_decision': 'no'},\n",
        "    {'age': '>40', 'income': 'high', 'student': 'no', 'credit_rating': 'excellent', 'purchase_decision': 'no'}\n",
        "]\n",
        "\n",
        "# Calculate the total number of instances\n",
        "total_new_samples = len(new_samples)\n",
        "\n",
        "# Determine the prior probabilities for each decision\n",
        "unique_decisions = set(sample['purchase_decision'] for sample in new_samples)\n",
        "prior_probs = {}\n",
        "\n",
        "for decision_label in unique_decisions:\n",
        "    decision_count = sum(1 for sample in new_samples if sample['purchase_decision'] == decision_label)\n",
        "    prior_probs[decision_label] = decision_count / total_new_samples\n",
        "\n",
        "print(\"Prior Probabilities for New Data:\")\n",
        "for decision_label, prior_prob in prior_probs.items():\n",
        "    print(f\"P({decision_label}) = {prior_prob:.4f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9DAVEIxC37Y"
      },
      "source": [
        "A2.Calculate the class conditional densities for various features & classes. Observe if any class conditional density has zero values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTU5PoPCC37a",
        "outputId": "1defad21-9ee2-4492-e4c7-dff08784be7e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Class Conditional Probabilities (Updated):\n",
            "For decision yes:\n",
            "P(age | yes) = 14.0000\n",
            "P(income | yes) = 14.0000\n",
            "P(student | yes) = 14.0000\n",
            "P(credit_rating | yes) = 14.0000\n",
            "For decision no:\n",
            "P(age | no) = 14.0000\n",
            "P(income | no) = 14.0000\n",
            "P(student | no) = 14.0000\n",
            "P(credit_rating | no) = 14.0000\n",
            "\n",
            "No features have zero class conditional probabilities (Updated).\n"
          ]
        }
      ],
      "source": [
        "# Initialize dictionaries to store class-specific conditional probabilities\n",
        "class_conditional_probs_updated = defaultdict(dict)  # defaultdict, a dictionary-like object, is employed here\n",
        "\n",
        "# Calculate conditional probabilities for each feature and class\n",
        "for feature_label in new_samples[0].keys():  # Assuming features are in the first dictionary\n",
        "    if feature_label != 'purchase_decision':  # Exclude the class label\n",
        "        for decision_label_updated in unique_decisions:\n",
        "            # Filter instances with the given feature and decision label\n",
        "            feature_decision_instances = [sample_updated for sample_updated in new_samples if sample_updated['purchase_decision'] == decision_label_updated and sample_updated[feature_label] == sample_updated[feature_label]]\n",
        "\n",
        "            # Calculate class conditional probability\n",
        "            probability_updated = len(feature_decision_instances) / prior_probs[decision_label_updated]\n",
        "            class_conditional_probs_updated[decision_label_updated][feature_label] = probability_updated\n",
        "\n",
        "# Display the class conditional probabilities\n",
        "print(\"Class Conditional Probabilities (Updated):\")\n",
        "for decision_label_updated, probabilities_updated in class_conditional_probs_updated.items():\n",
        "    print(f\"For decision {decision_label_updated}:\")\n",
        "    for feature_label, probability_updated in probabilities_updated.items():\n",
        "        print(f\"P({feature_label} | {decision_label_updated}) = {probability_updated:.4f}\")\n",
        "\n",
        "# Check for any class conditional probability with zero values\n",
        "zero_prob_features_updated = [(decision_label_updated, feature_label) for decision_label_updated, probabilities_updated in class_conditional_probs_updated.items() for feature_label, probability_updated in probabilities_updated.items() if probability_updated == 0]\n",
        "\n",
        "if zero_prob_features_updated:\n",
        "    print(\"\\nFeatures with zero class conditional probabilities (Updated):\")\n",
        "    for decision_label_updated, feature_label in zero_prob_features_updated:\n",
        "        print(f\"For decision {decision_label_updated}, feature {feature_label} has zero probability.\")\n",
        "else:\n",
        "    print(\"\\nNo features have zero class conditional probabilities (Updated).\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bxmPhr4kC37d"
      },
      "source": [
        "A3. Test for independence between the 4 given features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0aBo2zB3C37f",
        "outputId": "1f608a75-6b37-44b3-fccb-c2e2bc418a3e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-squared value (Updated): 0.0\n",
            "P-value (Updated): 1.0\n",
            "\n",
            "Test Result (Updated):\n",
            "Fail to reject the null hypothesis. Features are independent.\n"
          ]
        }
      ],
      "source": [
        "# Chi-squared test for independence - Null hypothesis: The two variables are independent\n",
        "\n",
        "# Extract features and labels from the updated dataset\n",
        "age_vals = [sample_updated['age'] for sample_updated in new_samples]\n",
        "income_vals = [sample_updated['income'] for sample_updated in new_samples]\n",
        "student_status = [sample_updated['student'] for sample_updated in new_samples]\n",
        "credit_rating_vals = [sample_updated['credit_rating'] for sample_updated in new_samples]\n",
        "purchase_decision = [sample_updated['purchase_decision'] for sample_updated in new_samples]\n",
        "\n",
        "# Create a set of unique values for each feature\n",
        "unique_vals = {\n",
        "    'age': set(age_vals),\n",
        "    'income': set(income_vals),\n",
        "    'student': set(student_status),\n",
        "    'credit_rating': set(credit_rating_vals),\n",
        "    'purchase_decision': set(purchase_decision)\n",
        "}\n",
        "\n",
        "# Generate all possible combinations of values for the features\n",
        "combinations_updated = list(product(unique_vals['age'], unique_vals['income'], unique_vals['student'], unique_vals['credit_rating'], unique_vals['purchase_decision']))\n",
        "\n",
        "# Construct a contingency table with Laplace smoothing\n",
        "contingency_table_updated = []\n",
        "epsilon_updated = 1e-10  # small constant to prevent zero expected frequencies\n",
        "\n",
        "for age_val, inc_val, stud_val, credit_val, decision_val in combinations_updated:\n",
        "    count_updated = sum(1 for i in range(total_new_samples) if age_vals[i] == age_val and purchase_decision[i] == decision_val and income_vals[i] == inc_val and student_status[i] == stud_val and credit_rating_vals[i] == credit_val)\n",
        "    contingency_table_updated.append([count_updated + epsilon_updated])\n",
        "\n",
        "# Perform Chi-squared test for independence\n",
        "chi2_updated, p_updated, _, _ = chi2_contingency(contingency_table_updated)\n",
        "\n",
        "# Display the test results\n",
        "print(f\"Chi-squared value (Updated): {chi2_updated}\")\n",
        "print(f\"P-value (Updated): {p_updated}\")\n",
        "\n",
        "# Set the significance level (e.g., alpha = 0.05)\n",
        "alpha_updated = 0.05    # alpha can be set to any value between 0 and 1\n",
        "print(\"\\nTest Result (Updated):\")\n",
        "if p_updated < alpha_updated:\n",
        "    print(\"Reject the null hypothesis. Features are not independent.\")\n",
        "else:\n",
        "    print(\"Fail to reject the null hypothesis. Features are independent.\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gZEks54RC37h"
      },
      "source": [
        "A4. Build a Naïve-Bayes (NB) classifier for the above given data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YbFg0cxUC37i",
        "outputId": "ac8edd2d-ba3a-4bed-f97c-6889daaf4f03"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Updated): 66.67%\n"
          ]
        }
      ],
      "source": [
        "# Extract features and target variable for the updated dataset\n",
        "data_features_updated = np.array([[sample_updated['age'], sample_updated['income'], sample_updated['student'], sample_updated['credit_rating']] for sample_updated in new_samples])\n",
        "target_variable_updated = np.array([sample_updated['purchase_decision'] for sample_updated in new_samples])\n",
        "\n",
        "# Utilize LabelEncoder to convert categorical data to numerical values\n",
        "label_encoder_updated = LabelEncoder()\n",
        "for i_updated in range(data_features_updated.shape[1]):\n",
        "    data_features_updated[:, i_updated] = label_encoder_updated.fit_transform(data_features_updated[:, i_updated])\n",
        "\n",
        "# Convert features to numeric values\n",
        "data_features_updated = data_features_updated.astype(float)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train_data_updated, X_test_data_updated, y_train_data_updated, y_test_data_updated = train_test_split(data_features_updated, target_variable_updated, test_size=0.2, random_state=42)\n",
        "\n",
        "# Establish and train the Gaussian Naive Bayes classifier for the updated dataset\n",
        "gnb_classifier_data_updated = GaussianNB()\n",
        "gnb_classifier_data_updated.fit(X_train_data_updated, y_train_data_updated)\n",
        "\n",
        "# Generate predictions on the test set for the updated dataset\n",
        "predictions_data_updated = gnb_classifier_data_updated.predict(X_test_data_updated)\n",
        "\n",
        "# Evaluate the classifier's performance for the updated dataset\n",
        "accuracy_data_updated = np.sum(predictions_data_updated == y_test_data_updated) / len(y_test_data_updated)\n",
        "print(f'Accuracy (Updated): {accuracy_data_updated:.2%}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jCD8WKpC37j"
      },
      "source": [
        "A5. Build a NB classifier for your own project data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIh3PL_FC37j",
        "outputId": "5809a2c5-e32a-46e7-f144-ec242e10b1aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy (Updated): 55.00%\n"
          ]
        }
      ],
      "source": [
        "# Read data from Excel file for the new dataset\n",
        "excel_data_updated = pd.read_excel('/content/embeddingsdata.xlsx')\n",
        "\n",
        "# Extract features and target for the updated dataset\n",
        "input_feats_updated = excel_data_updated.iloc[:, :-1]  # Features\n",
        "output_target_updated = excel_data_updated.iloc[:, -1]      # Target data\n",
        "\n",
        "# Utilize LabelEncoder to convert categorical data to numerical values\n",
        "label_encoder_excel_updated = LabelEncoder()\n",
        "for column_updated in input_feats_updated.columns:\n",
        "    input_feats_updated[column_updated] = label_encoder_excel_updated.fit_transform(input_feats_updated[column_updated])\n",
        "\n",
        "# Convert features to numeric values\n",
        "input_feats_updated = input_feats_updated.astype(float)\n",
        "\n",
        "# Split the data into training and testing sets for the updated dataset\n",
        "train_feats_excel_updated, test_feats_excel_updated, train_target_excel_updated, test_target_excel_updated = train_test_split(input_feats_updated, output_target_updated, test_size=0.2, random_state=42)\n",
        "\n",
        "# Establish and train the Gaussian Naive Bayes classifier for the updated dataset\n",
        "gnb_classifier_excel_updated = GaussianNB()\n",
        "gnb_classifier_excel_updated.fit(train_feats_excel_updated, train_target_excel_updated)\n",
        "\n",
        "# Make predictions on the test set for the updated dataset\n",
        "predictions_excel_updated = gnb_classifier_excel_updated.predict(test_feats_excel_updated)\n",
        "\n",
        "# Evaluate the classifier's performance for the updated dataset\n",
        "accuracy_excel_updated = np.sum(predictions_excel_updated == test_target_excel_updated) / len(test_target_excel_updated)\n",
        "print(f'Accuracy (Updated): {accuracy_excel_updated:.2%}')\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}